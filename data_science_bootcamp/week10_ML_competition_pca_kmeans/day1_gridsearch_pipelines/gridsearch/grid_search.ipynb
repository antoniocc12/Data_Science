{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36464bitc2077ed07ea84d23aa5b518d224882ab",
   "display_name": "Python 3.6.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is GridSearch?\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data.\n",
    "\n",
    "https://towardsdatascience.com/gridsearch-the-ultimate-machine-learning-tool-6cd5fb93d07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The “Grid” in GridSearch\n",
    "\n",
    "![grid](grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: One way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "clf.best_stimator_ SVC(C=0.5, coef0=-10.0, degree=1, kernel='linear')\nclf.best_params_ {'C': 0.5, 'coef0': -10.0, 'degree': 1, 'gamma': 'scale', 'kernel': 'linear'}\nclf.best_score 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 'kernel':('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "\n",
    "parameters = {\n",
    "    'kernel': ('linear', 'rbf', 'sigmoid'), \n",
    "    'C':[0.0001,0.1, 0.5, 1, 5, 10, 100], \n",
    "    'degree': [1,2,3,4,5,6,7,8,9],\n",
    "    'coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "    'gamma': ('scale', 'auto')\n",
    "    }\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "clf = GridSearchCV(estimator=svc, param_grid=parameters, n_jobs=-1, cv=10)\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"clf.best_stimator_\", clf.best_estimator_)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Almost-Pro way\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "\n",
    "# Le podemos poner cualquier clasificador. Irá cambiando según va probando pero necesita 1.\n",
    "pipe = Pipeline(steps=[('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10)\n",
    "    }\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "svm_params = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__kernel':('linear', 'rbf', 'sigmoid'), \n",
    "    'classifier__C':[0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "    'classifier__degree': to_test,\n",
    "    'classifier__coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "    'classifier__gamma': ('scale', 'auto')\n",
    "    }\n",
    "\n",
    "# hypertuning \n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 3485 candidates, totalling 34850 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 7160 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 22960 tasks      | elapsed:   13.4s\n",
      "\n",
      "############################\n",
      "\n",
      "best estimator: SVC(C=0.5, coef0=-10.0, degree=1, kernel='linear')\n",
      "\n",
      "############################\n",
      "\n",
      "clf.best_params_ {'classifier': SVC(C=0.5, coef0=-10.0, degree=1, kernel='linear'), 'classifier__C': 0.5, 'classifier__coef0': -10.0, 'classifier__degree': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n",
      "\n",
      "############################\n",
      "\n",
      "clf.best_score 0.9916666666666666\n",
      "Wall time: 18.5 s\n",
      "[Parallel(n_jobs=-1)]: Done 34835 out of 34850 | elapsed:   18.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 34850 out of 34850 | elapsed:   18.3s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# Create grid search \n",
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space, cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best model\n",
    "separator = \"\\n############################\\n\"\n",
    "print(separator)\n",
    "svc_ganador_entrado = best_model.best_estimator_.get_params()['classifier']\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(separator)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "print(separator)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'finished_model.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + os.sep\n",
    "full_file_name = path + \"finished_model.sav\"\n",
    "loaded_model = pickle.load(open(full_file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sklearn.svm._classes.SVC"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "type(svc_ganador_entrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Another way - No pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                    'gamma': [1e-3, 1e-4], \n",
    "                    'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], \n",
    "                    'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "######################################\n",
      "########## SCORE precision ########### \n",
      "######################################\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "######################################\n",
      "########## SCORE recall ########### \n",
      "######################################\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bar = \"######################################\"\n",
    "for score in scores:\n",
    "    print(bar + \"\\n########## SCORE \" + score + \" ########### \\n\" + bar)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(estimator=SVC(), param_grid=tuned_parameters, scoring=str(score)+'_macro')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}